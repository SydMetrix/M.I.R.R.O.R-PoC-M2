import json
import pickle
import faiss
import spacy
from transformers import AutoTokenizer, AutoModel
import torch
import numpy as np
from datetime import datetime
import os

# ====== Load SpaCy NLP model ======
print("Loading SpaCy model...")
nlp = spacy.load("en_core_web_sm")  # ho·∫∑c m√¥ h√¨nh ti·∫øng Vi·ªát n·∫øu c·∫ßn

# ====== Load Transformer model ======
print("Loading Transformer model for embeddings...")
tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
model = AutoModel.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")

# ====== Load FAISS index v√† th∆∞ vi·ªán vector ======
print("Loading FAISS index and vector library...")
index = faiss.read_index("concept_index.faiss")
with open("concept_metadata.pkl", "rb") as f:
    glitch_lib = pickle.load(f)

# ====== H√†m t·∫°o embedding c√¢u ======
def embed_text(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
    embeddings = outputs.last_hidden_state.mean(dim=1)  # mean pooling
    return embeddings[0].cpu().numpy()

# ====== H√†m Semantic Role Parsing ƒë∆°n gi·∫£n ======
def extract_roles(text):
    doc = nlp(text)
    roles = {"Agent": None, "Action": None, "Patient": None, "Location": None, "Manner": None}
    for token in doc:
        if token.dep_ == "nsubj":
            roles["Agent"] = token.text
        if token.dep_ == "ROOT":
            roles["Action"] = token.text
        if token.dep_ == "dobj":
            roles["Patient"] = token.text
        if token.dep_ == "prep":
            roles["Location"] = token.head.text + " " + token.text
    return roles

# ====== H√†m t√≠nh Component Semantic Similarity ======
def compare_roles(roles1, roles2):
    scores = []
    for key in roles1:
        if roles1[key] and roles2[key]:
            vec1 = embed_text(roles1[key])
            vec2 = embed_text(roles2[key])
            sim = cosine_similarity(vec1, vec2)
            scores.append(sim)
    if scores:
        return sum(scores) / len(scores), len(scores) / len(roles1)
    return 0.0, 0.0

# ====== H√†m cosine similarity ======
def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

# ====== H√†m chuy·ªÉn ƒë·ªïi numpy types sang Python native types ======
def convert_numpy_types(obj):
    """Chuy·ªÉn ƒë·ªïi c√°c ki·ªÉu d·ªØ li·ªáu numpy sang ki·ªÉu Python thu·∫ßn t√∫y ƒë·ªÉ c√≥ th·ªÉ serialize JSON"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, np.bool_):  # X·ª≠ l√Ω numpy boolean
        return bool(obj)
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    else:
        return obj

# ====== H√†m debug JSON file ======
def debug_json_file(filepath: str):
    """Debug file JSON ƒë·ªÉ t√¨m l·ªói"""
    if not os.path.exists(filepath):
        print(f"File {filepath} kh√¥ng t·ªìn t·∫°i.")
        return
    
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            content = f.read()
            print(f"üìÑ File size: {len(content)} characters")
            print(f"üìù First 200 chars: {content[:200]}")
            print(f"üìù Last 200 chars: {content[-200:]}")
            
            # Th·ª≠ parse JSON
            f.seek(0)
            data = json.load(f)
            print(f"‚úÖ JSON is valid! Type: {type(data)}")
            if isinstance(data, dict):
                print(f"üîë Keys: {list(data.keys())}")
    except json.JSONDecodeError as e:
        print(f"‚ùå JSON Error: {e}")
        print(f"üìç Error at line {e.lineno}, column {e.colno}")
        # Hi·ªÉn th·ªã context xung quanh l·ªói
        lines = content.split('\n')
        if e.lineno <= len(lines):
            print(f"üîç Problem line: {lines[e.lineno-1]}")
            if e.colno > 0:
                print(f"üîç Problem char: '{lines[e.lineno-1][e.colno-1:e.colno+10]}'")
    except Exception as e:
        print(f"‚ùå File Error: {e}")

# ====== H√†m save_to_json ho√†n ch·ªânh ======
def save_to_json(filepath: str, new_entry: dict):
    """
    L∆∞u entry m·ªõi v√†o file JSON. N·∫øu file ƒë√£ t·ªìn t·∫°i, load v√† append.
    N·∫øu file kh√¥ng t·ªìn t·∫°i ho·∫∑c b·ªã l·ªói, t·∫°o m·ªõi t·ª´ ƒë·∫ßu.
    
    Args:
        filepath (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn file JSON
        new_entry (dict): Entry m·ªõi c·∫ßn th√™m v√†o
    """
    # T·∫°o c·∫•u tr√∫c database m·∫∑c ƒë·ªãnh
    default_db = {
        "metadata": {
            "last_updated": None,
            "total_entries": 0,
            "version": "M2_GPR_v2"
        },
        "entries": []
    }
    
    # Th·ª≠ load file hi·ªán t·∫°i
    db = default_db.copy()
    if os.path.exists(filepath):
        print(f"üìÅ Found existing file: {filepath}")
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                loaded = json.load(f)
                if isinstance(loaded, dict) and "entries" in loaded and "metadata" in loaded:
                    db = loaded
                    print(f"‚úÖ Loaded existing database with {len(db['entries'])} entries.")
                else:
                    print("‚ö†Ô∏è Invalid format. Starting new database.")
        except json.JSONDecodeError as e:
            print(f"‚ùå JSON parsing error: {e}")
            print("üîç Debugging JSON file...")
            debug_json_file(filepath)
            # T·∫°o backup v√† t·∫°o file m·ªõi
            backup_path = filepath + ".backup"
            if os.path.exists(filepath):
                os.rename(filepath, backup_path)
                print(f"üìÑ Corrupted file backed up to: {backup_path}")
            print("üÜï Creating new database...")
        except Exception as e:
            print(f"‚ö†Ô∏è Warning: Could not load existing JSON. Reason: {e}")
            print("Proceeding with a new empty database.")
    else:
        print(f"üÜï Creating new database file: {filepath}")
    
    # T·∫°o entry_id m·ªõi
    new_entry["entry_id"] = len(db["entries"]) + 1
    new_entry["timestamp"] = datetime.now().isoformat()
    
    # Chuy·ªÉn ƒë·ªïi t·∫•t c·∫£ numpy types sang Python native types
    new_entry = convert_numpy_types(new_entry)
    
    # Th√™m entry m·ªõi
    db["entries"].append(new_entry)
    
    # C·∫≠p nh·∫≠t metadata
    db["metadata"]["last_updated"] = datetime.now().isoformat()
    db["metadata"]["total_entries"] = len(db["entries"])
    
    # Chuy·ªÉn ƒë·ªïi to√†n b·ªô database ƒë·ªÉ ƒë·∫£m b·∫£o JSON serializable
    db = convert_numpy_types(db)
    
    # Ghi v√†o file
    try:
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(db, f, indent=4, ensure_ascii=False)
        print(f"‚úÖ Entry saved successfully to {filepath}")
        print(f"üìä Total entries: {db['metadata']['total_entries']}")
    except Exception as e:
        print(f"‚ùå Error saving to JSON: {e}")
        print("Data types in new_entry:")
        for key, value in new_entry.get("results", {}).items():
            print(f"  {key}: {type(value)} = {value}")
        raise

# ====== Nh·∫≠n input ======
print("\nEnter Prompt:")
prompt = input()
print("\nEnter Response:")
response = input()

# ====== Semantic Embedding ======
print("Embedding prompt and response...")
prompt_vec = embed_text(prompt)
response_vec = embed_text(response)

# ====== T√≠nh to√°n Semantic Similarity ======
semantic_score = cosine_similarity(prompt_vec, response_vec)

# ====== Semantic Role Matching ======
prompt_roles = extract_roles(prompt)
response_roles = extract_roles(response)
component_score, role_match_ratio = compare_roles(prompt_roles, response_roles)
aggregated_srl_score = round(component_score * role_match_ratio, 3)

# ====== Glitch Signature Logic ======
glitch_types = []
if semantic_score < 0.75:
    glitch_types.append("SemanticSubLoop")
if aggregated_srl_score < 0.4:
    glitch_types.append("SkewedMirror")
if semantic_score > 0.7 and aggregated_srl_score > 0.3:
    glitch_types.append("SelfAffirmingTrap") 

glitch_signature = "GTP::" + "+".join(glitch_types) if glitch_types else "GTP::None"
csi_score = round(1.0 - ((semantic_score + aggregated_srl_score) / 2) * 0.5, 3)
# ====== CSI Reflection Labeling ======
if csi_score >= 0.8:
    csi_label = "üî¥ High Divergence"
elif csi_score >= 0.6:
    csi_label = "üü† Medium Divergence"
elif csi_score >= 0.4:
    csi_label = "üü° Mild Divergence"
else:
    csi_label = "üü¢ Stable"
    # Optional print to console
print(f"CSI Score: {csi_score} ‚Üí {csi_label}")
# ====== Route Decision Logic ======
route_sahl = csi_score < 0.5
route_arp_x = len(glitch_types) >= 2

# ====== In k·∫øt qu·∫£ ph√¢n t√≠ch ra m√†n h√¨nh ======
print("\n==== ANALYSIS RESULT ====")
print(f"Glitch Signature: {glitch_signature}")
print(f"Glitch Types: {glitch_types}")
print(f"CSI Score: {csi_score:.3f}")
print(f"Aggregated SRL Score: {aggregated_srl_score:.3f}")
print(f"Route SAHL: {route_sahl}")
print(f"Route ARP-X: {route_arp_x}")

# ====== H·ªèi ng∆∞·ªùi d√πng c√≥ mu·ªën l∆∞u kh√¥ng ======
save = input("\nSave to database? (y/n): ").strip().lower()
if save != 'y':
    print("\nResult discarded.")
    exit()

# ====== T·∫°o k·∫øt qu·∫£ m·ªõi ======
new_entry = {
    "input": {
        "prompt": prompt,
        "response": response
    },
    "results": {
        "glitch_signature": glitch_signature,
        "glitch_types": glitch_types,
        "csi_score": csi_score,
        "aggregated_srl_score": aggregated_srl_score,
        "route_sahl": route_sahl,
        "route_arp_x": route_arp_x
    }
}

# ====== S·ª≠ d·ª•ng h√†m save_to_json ======
json_path = "M2_results.json"
save_to_json(json_path, new_entry)